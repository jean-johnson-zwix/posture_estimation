# -*- coding: utf-8 -*-
"""posture_estimation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fAB9o9tAhpJ1VCO7Wczv6yupDIEFAH8g
"""

!pip -q install mediapipe opencv-python gradio fastrtc

!pip install --upgrade mediapipe==0.10.21

"""# MediaPipe Landmark Detection

## Download the model
"""

!wget -O pose_landmarker.task -q https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_lite.task

from google.colab import drive
drive.mount('/content/drive')

"""## Create Pose Landmarker (VIDEO MODE)"""

from mediapipe import solutions
from mediapipe.framework.formats import landmark_pb2
import numpy as np


def draw_landmarks_on_image(rgb_image, detection_result, thickness=4, circle_radius=6):
  pose_landmarks_list = detection_result.pose_landmarks
  annotated_image = np.copy(rgb_image)

  for pose_landmarks in pose_landmarks_list:
      pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()
      pose_landmarks_proto.landmark.extend([
          landmark_pb2.NormalizedLandmark(x=l.x, y=l.y, z=l.z) for l in pose_landmarks
      ])

      landmark_spec = solutions.drawing_utils.DrawingSpec(thickness=thickness, circle_radius=circle_radius)
      connection_spec = solutions.drawing_utils.DrawingSpec(thickness=thickness)

      solutions.drawing_utils.draw_landmarks(
          image=annotated_image,
          landmark_list=pose_landmarks_proto,
          connections=solutions.pose.POSE_CONNECTIONS,
          landmark_drawing_spec=landmark_spec,
          connection_drawing_spec=connection_spec,
      )

  return annotated_image

import mediapipe as mp

# VIDEO Model Landmarker
BaseOptions = mp.tasks.BaseOptions
PoseLandmarker = mp.tasks.vision.PoseLandmarker
PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions
VisionRunningMode = mp.tasks.vision.RunningMode

# Create a pose landmarker instance with the video mode:
options = PoseLandmarkerOptions(
    base_options=BaseOptions(model_asset_path='/content/pose_landmarker.task'),
    running_mode=VisionRunningMode.VIDEO)

landmarker = PoseLandmarker.create_from_options(options)

"""# Gradio Live Demo"""

from fastrtc import Stream
import time
import cv2
import gradio
from fastrtc import Stream, VideoStreamHandler, AdditionalOutputs

def process_frame(frame):
    global last_timestamp
    frame = np.asarray(frame)
    if frame.dtype != np.uint8:
        frame = frame.astype(np.uint8)
    # convert RGB to SRBG
    mediapipe_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)
    # detect the pose
    frame_timestamp = int(time.time_ns()//1000)
    try:
        result = landmarker.detect_for_video(mediapipe_image, frame_timestamp)
    except Exception as e:
        print(e)
        return frame, f"error: {e}"
    # visualize the pose
    annotated_frame = draw_landmarks_on_image(frame, result, thickness=5, circle_radius=8)
    return annotated_frame, "<posture estimation results>"


with gradio.Blocks() as demo:
    gradio.Markdown("## Posture Detection with MediaPipe PoseLandmarker")
    with gradio.Row():
        with gradio.Column():
            cam = gradio.Image(label="Webcam", sources="webcam", type="numpy")            
        with gradio.Column():
            out_img = gradio.Image(label="Annotated", streaming=True)
            out_md = gradio.Markdown()

    cam.stream(
        fn=process_frame,
        inputs=cam,
        outputs=[out_img, out_md],
        time_limit=60,
        stream_every=0.25,
        concurrency_limit=1
    )

demo.launch(share=True, debug=True)